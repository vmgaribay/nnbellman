{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.interpolate import interp1d\n",
    "from scipy.optimize import minimize_scalar\n",
    "\n",
    "from SALib.sample import saltelli,latin\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from scipy.interpolate import griddata\n",
    "\n",
    "\n",
    "# Input Variables\n",
    "# k (capital) 1-10 uniform, 1-15 uniform for random sample \n",
    "# Œ∏ (perceived shock factor) 0.1-1 uniform\n",
    "# œÉ (risk averseness) normal centered around 1.08\n",
    "# Œ± (aptitude/human capital) normal centered around 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/73/xt36gx2n50nfg3478nvjbx100000gn/T/ipykernel_92434/191297959.py:16: DeprecationWarning: `salib.sample.saltelli` will be removed in SALib 1.5. Please use `salib.sample.sobol`\n",
      "  S_sample=saltelli.sample(problem,n)\n"
     ]
    }
   ],
   "source": [
    "# Generate Samples\n",
    "\n",
    "# Saltelli Sample\n",
    "\n",
    "n=1024\n",
    "N=5000\n",
    "seed=1\n",
    "#2d+2=10\n",
    "\n",
    "problem={   \"names\": [\"Alpha\",\"k\",\"Sigma\",\"Theta\"], \n",
    "            \"num_vars\":4,\n",
    "            \"bounds\":[[1.08,0.074],[0.1,10],[1,0.5],[0.1,1]],\n",
    "            \"dists\":[\"norm\",\"unif\",\"norm\",\"unif\"]}\n",
    "            #\"seed\":seed\n",
    "\n",
    "S_sample=saltelli.sample(problem,n)\n",
    "\n",
    "\n",
    "S_sampledf=pd.DataFrame(S_sample, columns=[\"Alpha\",\"k\",\"Sigma\",\"Theta\"])\n",
    "\n",
    "S_sampledf[\"Sigma\"]=np.round(S_sampledf[\"Sigma\"],1)\n",
    "S_sampledf[\"Theta\"]=np.round(S_sampledf[\"Theta\"],1)\n",
    "S_sampledf.index.name=\"AgentID\"\n",
    "\n",
    "\n",
    "\n",
    "# # Latin Hypercube Sample\n",
    "# LH_sample=latin.sample(problem,N,seed)\n",
    "\n",
    "# LH_sampledf=pd.DataFrame(LH_sample, columns=[\"Alpha\",\"k\",\"Sigma\",\"Theta\"])\n",
    "\n",
    "# LH_sampledf[\"Sigma\"]=np.round(LH_sampledf[\"Sigma\"],1)\n",
    "# LH_sampledf[\"Theta\"]=np.round(LH_sampledf[\"Theta\"],1)\n",
    "# LH_sampledf.index.name=\"AgentID\"\n",
    "\n",
    "# # Random Sample\n",
    "# np.random.seed(seed)\n",
    "# alphas = np.random.normal(loc = 1.08, scale = 0.074, size = N) #list of agent alphas, effectively ability/human capital\n",
    "# capital = np.random.uniform(low = 0.1, high = 10, size = N) #list of agent initial capital amounts\n",
    "# sigmas=np.round(np.random.normal(loc = 1, scale = 0.5,size=N),1) #list of agent sigmas, effectively risk-averseness\n",
    "# thetas= np.round(np.random.uniform(low=0.1, high=1, size=N),1) #percieved theta (cannot be zero or the optimizer breaks because k<) maybe one day this can be spatial?\n",
    "# R_sampledf=pd.DataFrame({\"Alpha\":alphas,\"k\":capital,\"Sigma\":sigmas,\"Theta\":thetas})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# global variables for Bellman equation\n",
    "ùõø = 0.08 #depreciation\n",
    "Œ≤ = 0.95 #discount factor\n",
    "\n",
    "\n",
    "TechTable = {#contains values for 0:gamma 1:cost 2:theta\n",
    "# VMG things get stuck in a while loop if the gamma is less than 0.3 \n",
    "# (tried 0.2) not sure yet if/how this will be problematic \n",
    "# Also important to make sure values are in the correct order\n",
    "# i.e. that the threshold between medium and high is at a \n",
    "# higher k than the threshold between low and medium \n",
    "# This can be checked with k_threshold.py\n",
    "\n",
    "    \"low\":   [0.3,  0   ],\n",
    "    \"medium\":[0.35, 0.15],\n",
    "    \"high\":  [0.45, 0.65]}\n",
    "\n",
    "TechTableArray = np.array([[ 0.3,  0 ],[0.35, 0.15],[0.45, 0.65]])\n",
    "\n",
    "AdapTable = {\n",
    "    # contains values for 0:theta 1:cost \n",
    "    # (for consideration:effort? type? design life?)\n",
    "    \"none\":   [  0, 0   ],\n",
    "    \"good\":   [0.5, 0.25],\n",
    "    \"better\": [0.9, 0.45]}\n",
    "\n",
    "AdapTableArray = np.array([[ 0,  0 ],[0.5, 0.25],[0.9, 0.45]])\n",
    "\n",
    "\n",
    "\n",
    "# Define Optimization Routine:\n",
    "\n",
    "\n",
    "def maximize(g, a, b, args):\n",
    "    \"\"\"\n",
    "    From: https://python.quantecon.org/optgrowth.html (similar example \n",
    "    https://macroeconomics.github.io/Dynamic%20Programming.html#.ZC13-exBy3I)\n",
    "    Maximize the function g over the interval [a, b].\n",
    "\n",
    "    The maximizer of g on any interval is\n",
    "    also the minimizer of -g.  The tuple args collects any extra\n",
    "    arguments to g.\n",
    "\n",
    "    Returns the maximum value and the maximizer.\n",
    "    \"\"\"\n",
    "\n",
    "    objective = lambda x: -g(x, *args)\n",
    "    result = minimize_scalar(objective, bounds=(a, b), method='bounded')\n",
    "    maximizer, maximum = result.x, -result.fun\n",
    "    return maximizer, maximum\n",
    "\n",
    "def utility(c, œÉ, type=\"isoelastic\"):\n",
    "    if type == \"isoelastic\":\n",
    "        if œÉ ==1:\n",
    "            return np.log(c)\n",
    "        else:\n",
    "            return (c**(1-œÉ)-1)/(1-œÉ)\n",
    "\n",
    "    else:\n",
    "        print(\"Unspecified utility function!!!\")\n",
    "\n",
    "\n",
    "def income_function(k,Œ±): \n",
    "    f = []\n",
    "    for i in TechTable.keys(): \n",
    "        #in the end, they may need their own tech tables\n",
    "        entry = Œ± * k**TechTable[i][0] - TechTable[i][1]\n",
    "        f.append(entry)\n",
    "    return max(f)\n",
    "\n",
    "def adaptation_function(Œ∏,i_a):\n",
    "    \n",
    "    for i in AdapTable.keys(): \n",
    "        #in the end, they should have their own adaptation tables\n",
    "        if AdapTable[i][1] <= i_a:\n",
    "            m = AdapTable[i][0]\n",
    "        else:\n",
    "            break\n",
    "    return Œ∏ + m * (1-Œ∏)\n",
    "\n",
    "\n",
    "\n",
    "class BellmanEquation:\n",
    "     #Adapted from: https://python.quantecon.org/optgrowth.html\n",
    "    def __init__(self,\n",
    "                 u,            # utility function\n",
    "                 f,            # production function\n",
    "                 k,            # current state k_t\n",
    "                 Œ∏,            # given shock factor Œ∏\n",
    "                 œÉ,            # risk averseness\n",
    "                 Œ±,            # human capital\n",
    "                 i_a,          # adaptation investment\n",
    "                 m,            # protection multiplier\n",
    "                 Œ≤=Œ≤,          # discount factor\n",
    "                 ùõø=ùõø,          # depreciation factor \n",
    "                 name=\"BellmanNarrowExtended\"):\n",
    "\n",
    "        self.u, self.f, self.k, self.Œ≤, self.Œ∏, self.ùõø, self.œÉ, self.Œ±, self.i_a, self.m, self.name = u, f, k, Œ≤, Œ∏, ùõø, œÉ, Œ±, i_a, m, name\n",
    "\n",
    "        # Set up grid\n",
    "        \n",
    "        startgrid=np.array([1.0e-7,1,2,3,4,5,6,7,8,9,10,k+100])\n",
    "\n",
    "        ind=np.searchsorted(startgrid, k)\n",
    "        self.grid=np.concatenate((startgrid[:ind],np.array([k*0.99999, k]),\n",
    "                                 startgrid[ind:]))\n",
    "\n",
    "        self.grid=self.grid[self.grid>i_a]\n",
    "\n",
    "        # Identify target state k\n",
    "        self.index = np.searchsorted(self.grid, k)-1\n",
    "    \n",
    "    def value(self, c, y, v_array):\n",
    "        \"\"\"\n",
    "        Right hand side of the Bellman equation.\n",
    "        \"\"\"\n",
    "\n",
    "        u, f, Œ≤, Œ∏, ùõø, œÉ, Œ±, i_a, m = self.u, self.f, self.Œ≤, self.Œ∏, self.ùõø, self.œÉ, self.Œ±, self.i_a, self.m\n",
    "\n",
    "        v = interp1d(self.grid, v_array, bounds_error=False, \n",
    "                     fill_value=\"extrapolate\")\n",
    "        \n",
    "        return u(c,œÉ) + Œ≤ * v((Œ∏ + m * (1-Œ∏)) * (f(y,Œ±) - c - i_a + (1 - ùõø) * y))\n",
    "\n",
    "\n",
    "\n",
    "def update_bellman(v, bell):\n",
    "    \"\"\"\n",
    "    From: https://python.quantecon.org/optgrowth.html (similar example\n",
    "    https://macroeconomics.github.io/Dynamic%20Programming.html#.ZC13-exBy3I)\n",
    "    \n",
    "    The Bellman operator.  Updates the guess of the value function\n",
    "    and also computes a v-greedy policy.\n",
    "\n",
    "      * bell is an instance of Bellman equation\n",
    "      * v is an array representing a guess of the value function\n",
    "\n",
    "    \"\"\"\n",
    "    v_new = np.empty_like(v)\n",
    "    v_greedy = np.empty_like(v)\n",
    "    \n",
    "    for i in range(len(bell.grid)):\n",
    "        y = bell.grid[i]\n",
    "        # Maximize RHS of Bellman equation at state y\n",
    "        \n",
    "        c_star, v_max = maximize(bell.value, min([1e-8,y*0.00001]), \n",
    "                                 y-bell.i_a, (y, v))\n",
    "        #VMG HELP! can anyone check that (1) subtracting i_a and \n",
    "        # (2) omitting any grid values less than i_a \n",
    "        # will not be problematic? The only thing I can come up with\n",
    "        # is if i_a is greater than k*0.99999\n",
    "        # which_bellman() now accounts for that case. Whole thing \n",
    "        # could use refinement.\n",
    "      \n",
    "        v_new[i] = v_max\n",
    "        v_greedy[i] = c_star\n",
    "\n",
    "    return v_greedy, v_new\n",
    "\n",
    "def which_bellman(agentinfo):\n",
    "    \"\"\"\n",
    "    Solves bellman for each affordable adaptation option.\n",
    "    \"\"\"\n",
    "    feasible=[]\n",
    "\n",
    "\n",
    "    for option in agentinfo.adapt:\n",
    "        if option[1]>=(income_function(agentinfo.k,agentinfo.Œ±)+(1-ùõø)*agentinfo.k)*0.99998:\n",
    "            # ensures that the gridpoint\n",
    "            # just below income, income*0.99999, is included\n",
    "            pass\n",
    "        else:\n",
    "            #print(f'working theta = {agentinfo.Œ∏ + option[0] *\\\n",
    "            #  (1-agentinfo.Œ∏)}, i_a= {option[1]}, k= {agentinfo.k}')\n",
    "            c,v=solve_bellman(BellmanEquation(u=utility, \n",
    "                              f=income_function, k=agentinfo.k, \n",
    "                              Œ∏=agentinfo.Œ∏, œÉ=agentinfo.œÉ, \n",
    "                              Œ±=agentinfo.Œ±, i_a=option[1],m=option[0]))\n",
    "            feasible.append([v,c,option[1],option[0]])\n",
    "\n",
    "    best=min(feasible)\n",
    "\n",
    "    \n",
    "    return feasible\n",
    "\n",
    "\n",
    "\n",
    "def solve_bellman(bell,\n",
    "                  tol=1,\n",
    "                  min_iter=10,\n",
    "                  max_iter=1000,\n",
    "                  verbose=False):\n",
    "    \"\"\"\n",
    "    From: https://python.quantecon.org/optgrowth.html (similar example\n",
    "    https://macroeconomics.github.io/Dynamic%20Programming.html#.ZC13-exBy3I)\n",
    "    \n",
    "    Solve model by iterating with the Bellman operator.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    # Set up loop\n",
    "\n",
    "    v = bell.u(bell.grid,bell.œÉ)  # Initial condition\n",
    "    i = 0\n",
    "    error = tol + 1\n",
    "    max_error = tol*10 + 1\n",
    "\n",
    "    while (i < max_iter and (error > tol or max_error > tol*10)) or (i < min_iter):\n",
    "        v_greedy, v_new = update_bellman(v, bell)\n",
    "        error = np.abs(v[bell.index] - v_new)[bell.index]\n",
    "        max_error = np.max(np.abs(v - v_new))\n",
    "        i += 1\n",
    "        # if verbose and i % print_skip == 0:\n",
    "        #     print(f\"Error at iteration {i} is {error}.\")\n",
    "        v = v_new\n",
    "\n",
    "    if (error > tol) or (max_error > tol*10):\n",
    "        print(f\"{bell.name} failed to converge for k={bell.k}, Œ± = {bell.Œ±},œÉ ={bell.œÉ}, i_a={bell.i_a}, and modified Œ∏ = {bell.Œ∏ + bell.m * (1-bell.Œ∏)} after {i} iterations!\")\n",
    "    elif verbose:\n",
    "        print(f\"Converged in {i} iterations.\")\n",
    "        print(f\"Effective k and new c {np.around(bell.grid[bell.index],3),v_greedy[bell.index]}.\")\n",
    "        \n",
    "\n",
    "    return v_greedy[bell.index],v[bell.index]\n",
    "\n",
    " \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtain Output for Samples\n",
    "class agent:\n",
    "    def __init__(self,\n",
    "                 k,            # current state k_t\n",
    "                 Œ∏,            # perceived shock factor Œ∏\n",
    "                 œÉ,            # risk averseness\n",
    "                 Œ±,            # human capital\n",
    "                 adapt):       # AdapTable \n",
    "        self.k,self.Œ∏, self.œÉ, self.Œ±, self.adapt=k,Œ∏,œÉ,Œ±,adapt\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "# Saltelli\n",
    "S1_ResultsN=pd.DataFrame({'Agent':[],'Value':[],'Consumption':[], 'i_a':[], 'm':[]})\n",
    "S1_ResultsL=pd.DataFrame({'Agent':[],'Value':[],'Consumption':[], 'i_a':[], 'm':[]})\n",
    "S1_ResultsH=pd.DataFrame({'Agent':[],'Value':[],'Consumption':[], 'i_a':[], 'm':[]})\n",
    "for i in range(len(S_sampledf)):#len(S_sampledf)):\n",
    "    info=agent(k=S_sampledf.loc[i,\"k\"], Œ∏=S_sampledf.loc[i,\"Theta\"], œÉ=S_sampledf.loc[i,\"Sigma\"], Œ±=S_sampledf.loc[i,\"Alpha\"],adapt=AdapTableArray)\n",
    "    feasible=which_bellman(info)\n",
    "    if len(feasible)>2:\n",
    "        S1_ResultsH.loc[i]=[f\"S{i}\",*feasible[2]]\n",
    "    if len(feasible)>1:\n",
    "        S1_ResultsL.loc[i]=[f\"S{i}\",*feasible[1]]\n",
    "    S1_ResultsN.loc[i]=[f\"S{i}\",*feasible[0]]\n",
    "    \n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 N         L         H\n",
      "0        -3.394385 -0.507725 -1.612997\n",
      "1         1.084136  1.101250  0.516426\n",
      "2        -3.089501 -0.108840 -1.046469\n",
      "3        -2.646583 -0.474797 -1.508955\n",
      "4   -169573.406747 -3.360168 -3.120720\n",
      "..             ...       ...       ...\n",
      "495       2.685924  3.177098  4.045784\n",
      "496       2.025169  2.476986  3.187560\n",
      "497      -0.478427  2.543510  3.334741\n",
      "498     -62.310492  0.348477  2.680253\n",
      "499       2.218366  2.718031  3.498606\n",
      "\n",
      "[500 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "print(pd.DataFrame({\"N\":S1_ResultsN[\"Value\"], \"L\":S1_ResultsL[\"Value\"], \"H\":S1_ResultsH[\"Value\"]}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tol 0.1\n",
    "\n",
    "def solve_bellman(bell,\n",
    "                  tol=0.1,\n",
    "                  min_iter=10,\n",
    "                  max_iter=1000,\n",
    "                  verbose=False):\n",
    "    \"\"\"\n",
    "    From: https://python.quantecon.org/optgrowth.html (similar example\n",
    "    https://macroeconomics.github.io/Dynamic%20Programming.html#.ZC13-exBy3I)\n",
    "    \n",
    "    Solve model by iterating with the Bellman operator.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    # Set up loop\n",
    "\n",
    "    v = bell.u(bell.grid,bell.œÉ)  # Initial condition\n",
    "    i = 0\n",
    "    error = tol + 1\n",
    "    max_error = tol*10 + 1\n",
    "\n",
    "    while (i < max_iter and (error > tol or max_error > tol*10)) or (i < min_iter):\n",
    "        v_greedy, v_new = update_bellman(v, bell)\n",
    "        error = np.abs(v[bell.index] - v_new)[bell.index]\n",
    "        max_error = np.max(np.abs(v - v_new))\n",
    "        i += 1\n",
    "        # if verbose and i % print_skip == 0:\n",
    "        #     print(f\"Error at iteration {i} is {error}.\")\n",
    "        v = v_new\n",
    "\n",
    "    if (error > tol) or (max_error > tol*10):\n",
    "        print(f\"{bell.name} failed to converge for k={bell.k}, Œ± = {bell.Œ±},œÉ ={bell.œÉ}, i_a={bell.i_a}, and modified Œ∏ = {bell.Œ∏ + bell.m * (1-bell.Œ∏)} after {i} iterations!\")\n",
    "    elif verbose:\n",
    "        print(f\"Converged in {i} iterations.\")\n",
    "        print(f\"Effective k and new c {np.around(bell.grid[bell.index],3),v_greedy[bell.index]}.\")\n",
    "        \n",
    "\n",
    "    return v_greedy[bell.index],v[bell.index]\n",
    "\n",
    " # Obtain Output for Samples\n",
    "class agent:\n",
    "    def __init__(self,\n",
    "                 k,            # current state k_t\n",
    "                 Œ∏,            # perceived shock factor Œ∏\n",
    "                 œÉ,            # risk averseness\n",
    "                 Œ±,            # human capital\n",
    "                 adapt):       # AdapTable \n",
    "        self.k,self.Œ∏, self.œÉ, self.Œ±, self.adapt=k,Œ∏,œÉ,Œ±,adapt\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "# Saltelli\n",
    "STenth_ResultsN=pd.DataFrame({'Agent':[],'Value':[],'Consumption':[], 'i_a':[], 'm':[]})\n",
    "STenth_ResultsL=pd.DataFrame({'Agent':[],'Value':[],'Consumption':[], 'i_a':[], 'm':[]})\n",
    "STenth_ResultsH=pd.DataFrame({'Agent':[],'Value':[],'Consumption':[], 'i_a':[], 'm':[]})\n",
    "for i in range(len(S_sampledf)):#len(S_sampledf)):\n",
    "    info=agent(k=S_sampledf.loc[i,\"k\"], Œ∏=S_sampledf.loc[i,\"Theta\"], œÉ=S_sampledf.loc[i,\"Sigma\"], Œ±=S_sampledf.loc[i,\"Alpha\"],adapt=AdapTableArray)\n",
    "    feasible=which_bellman(info)\n",
    "    if len(feasible)>2:\n",
    "        STenth_ResultsH.loc[i]=[f\"S{i}\",*feasible[2]]\n",
    "    if len(feasible)>1:\n",
    "        STenth_ResultsL.loc[i]=[f\"S{i}\",*feasible[1]]\n",
    "    STenth_ResultsN.loc[i]=[f\"S{i}\",*feasible[0]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 N         L          H\n",
      "0        -3.406300 -5.701979  -8.987846\n",
      "1         1.081514  0.798566  -0.976655\n",
      "2        -3.101417 -5.224954  -8.290181\n",
      "3        -3.127967 -5.226291  -8.156691\n",
      "4   -169589.913333 -9.786140 -16.005159\n",
      "..             ...       ...        ...\n",
      "495       0.292817  0.416264   2.027577\n",
      "496      -1.010402 -1.092142  -0.257316\n",
      "497      -1.994235 -1.068638  -0.023402\n",
      "498     -80.513513 -4.421133  -2.536916\n",
      "499      -0.817090 -0.845174   0.090783\n",
      "\n",
      "[500 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "#print(S_ResultsN[\"Value\"])\n",
    "print(pd.DataFrame({\"N\":STenth_ResultsN[\"Value\"], \"L\":STenth_ResultsL[\"Value\"], \"H\":STenth_ResultsH[\"Value\"]}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BellmanNarrowExtended failed to converge for k=6.9207519531249995, Œ± = 1.1164759545940166,œÉ =-0.2, i_a=0.0, and modified Œ∏ = 0.9 after 2000 iterations!\n",
      "BellmanNarrowExtended failed to converge for k=0.414208984375, Œ± = 1.1025334668114688,œÉ =-0.2, i_a=0.0, and modified Œ∏ = 0.9 after 2000 iterations!\n",
      "BellmanNarrowExtended failed to converge for k=9.202392578125, Œ± = 1.0544107175248696,œÉ =-0.1, i_a=0.0, and modified Œ∏ = 1.0 after 2000 iterations!\n",
      "BellmanNarrowExtended failed to converge for k=2.647509765625, Œ± = 1.1649505662161492,œÉ =-0.2, i_a=0.45, and modified Œ∏ = 0.91 after 2000 iterations!\n",
      "BellmanNarrowExtended failed to converge for k=5.4222167968749995, Œ± = 1.1649505662161492,œÉ =-0.2, i_a=0.25, and modified Œ∏ = 0.95 after 2000 iterations!\n",
      "BellmanNarrowExtended failed to converge for k=2.647509765625, Œ± = 1.0617942630442245,œÉ =-0.2, i_a=0.0, and modified Œ∏ = 0.9 after 2000 iterations!\n",
      "BellmanNarrowExtended failed to converge for k=2.647509765625, Œ± = 1.0617942630442245,œÉ =-0.2, i_a=0.45, and modified Œ∏ = 0.99 after 2000 iterations!\n",
      "BellmanNarrowExtended failed to converge for k=5.4222167968749995, Œ± = 1.0617942630442245,œÉ =-0.2, i_a=0.0, and modified Œ∏ = 0.9 after 2000 iterations!\n",
      "BellmanNarrowExtended failed to converge for k=9.337744140625, Œ± = 1.0640268047640689,œÉ =-0.6, i_a=0.0, and modified Œ∏ = 0.9 after 2000 iterations!\n",
      "BellmanNarrowExtended failed to converge for k=1.4390136718750002, Œ± = 1.0640268047640689,œÉ =-0.6, i_a=0.25, and modified Œ∏ = 0.6499999999999999 after 2000 iterations!\n",
      "BellmanNarrowExtended failed to converge for k=2.299462890625, Œ± = 1.1264415610453238,œÉ =-0.2, i_a=0.45, and modified Œ∏ = 0.9299999999999999 after 2000 iterations!\n",
      "BellmanNarrowExtended failed to converge for k=5.054833984375, Œ± = 0.99574586706938,œÉ =-0.4, i_a=0.45, and modified Œ∏ = 0.97 after 2000 iterations!\n",
      "BellmanNarrowExtended failed to converge for k=1.6807128906250002, Œ± = 0.99574586706938,œÉ =-0.4, i_a=0.0, and modified Œ∏ = 0.9 after 2000 iterations!\n",
      "BellmanNarrowExtended failed to converge for k=5.054833984375, Œ± = 1.1595744938903447,œÉ =-0.4, i_a=0.0, and modified Œ∏ = 0.9 after 2000 iterations!\n",
      "BellmanNarrowExtended failed to converge for k=1.6807128906250002, Œ± = 1.1595744938903447,œÉ =-0.4, i_a=0.0, and modified Œ∏ = 0.7 after 2000 iterations!\n",
      "BellmanNarrowExtended failed to converge for k=1.6807128906250002, Œ± = 1.1595744938903447,œÉ =-0.4, i_a=0.25, and modified Œ∏ = 0.85 after 2000 iterations!\n",
      "BellmanNarrowExtended failed to converge for k=1.6807128906250002, Œ± = 1.1595744938903447,œÉ =-0.4, i_a=0.0, and modified Œ∏ = 0.9 after 2000 iterations!\n",
      "BellmanNarrowExtended failed to converge for k=2.686181640625, Œ± = 1.1025334668114688,œÉ =-0.2, i_a=0.45, and modified Œ∏ = 0.9200000000000002 after 2000 iterations!\n",
      "BellmanNarrowExtended failed to converge for k=2.686181640625, Œ± = 1.0959731952359313,œÉ =-0.2, i_a=0.45, and modified Œ∏ = 0.9200000000000002 after 2000 iterations!\n",
      "BellmanNarrowExtended failed to converge for k=1.4196777343750002, Œ± = 1.111840698261931,œÉ =-0.4, i_a=0.25, and modified Œ∏ = 0.75 after 2000 iterations!\n",
      "BellmanNarrowExtended failed to converge for k=1.4196777343750002, Œ± = 1.157037824500409,œÉ =-0.4, i_a=0.25, and modified Œ∏ = 0.75 after 2000 iterations!\n",
      "BellmanNarrowExtended failed to converge for k=1.4196777343750002, Œ± = 1.111840698261931,œÉ =-0.4, i_a=0.0, and modified Œ∏ = 0.8 after 2000 iterations!\n",
      "BellmanNarrowExtended failed to converge for k=2.2221191406250003, Œ± = 1.157037824500409,œÉ =-0.4, i_a=0.25, and modified Œ∏ = 0.9 after 2000 iterations!\n",
      "BellmanNarrowExtended failed to converge for k=1.1006347656250002, Œ± = 1.179064775640082,œÉ =-0.2, i_a=0.45, and modified Œ∏ = 0.96 after 2000 iterations!\n",
      "BellmanNarrowExtended failed to converge for k=1.013623046875, Œ± = 1.0831709736914719,œÉ =-0.1, i_a=0.25, and modified Œ∏ = 1.0 after 2000 iterations!\n",
      "BellmanNarrowExtended failed to converge for k=1.2746582031250002, Œ± = 1.1052050183981035,œÉ =-0.6, i_a=0.25, and modified Œ∏ = 0.6499999999999999 after 2000 iterations!\n",
      "BellmanNarrowExtended failed to converge for k=1.2746582031250002, Œ± = 1.1052050183981035,œÉ =-0.6, i_a=0.45, and modified Œ∏ = 0.9299999999999999 after 2000 iterations!\n",
      "BellmanNarrowExtended failed to converge for k=1.2746582031250002, Œ± = 1.076647707165119,œÉ =-0.6, i_a=0.25, and modified Œ∏ = 0.7 after 2000 iterations!\n",
      "BellmanNarrowExtended failed to converge for k=1.2746582031250002, Œ± = 1.076647707165119,œÉ =-0.6, i_a=0.45, and modified Œ∏ = 0.9400000000000001 after 2000 iterations!\n",
      "BellmanNarrowExtended failed to converge for k=1.2746582031250002, Œ± = 1.076647707165119,œÉ =-0.6, i_a=0.25, and modified Œ∏ = 0.6499999999999999 after 2000 iterations!\n",
      "BellmanNarrowExtended failed to converge for k=6.224658203125, Œ± = 1.2350617970992785,œÉ =-0.5, i_a=0.0, and modified Œ∏ = 0.8 after 2000 iterations!\n",
      "BellmanNarrowExtended failed to converge for k=6.224658203125, Œ± = 1.2350617970992785,œÉ =-0.5, i_a=0.25, and modified Œ∏ = 0.9 after 2000 iterations!\n"
     ]
    }
   ],
   "source": [
    "#Tol 0.01\n",
    "\n",
    "def solve_bellman(bell,\n",
    "                  tol=0.01,\n",
    "                  min_iter=10,\n",
    "                  max_iter=2000,\n",
    "                  verbose=False):\n",
    "    \"\"\"\n",
    "    From: https://python.quantecon.org/optgrowth.html (similar example\n",
    "    https://macroeconomics.github.io/Dynamic%20Programming.html#.ZC13-exBy3I)\n",
    "    \n",
    "    Solve model by iterating with the Bellman operator.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    # Set up loop\n",
    "\n",
    "    v = bell.u(bell.grid,bell.œÉ)  # Initial condition\n",
    "    i = 0\n",
    "    error = tol + 1\n",
    "    max_error = tol*10 + 1\n",
    "\n",
    "    while (i < max_iter and (error > tol or max_error > tol*10)) or (i < min_iter):\n",
    "        v_greedy, v_new = update_bellman(v, bell)\n",
    "        error = np.abs(v[bell.index] - v_new)[bell.index]\n",
    "        max_error = np.max(np.abs(v - v_new))\n",
    "        i += 1\n",
    "        # if verbose and i % print_skip == 0:\n",
    "        #     print(f\"Error at iteration {i} is {error}.\")\n",
    "        v = v_new\n",
    "\n",
    "    if (error > tol) or (max_error > tol*10):\n",
    "        print(f\"{bell.name} failed to converge for k={bell.k}, Œ± = {bell.Œ±},œÉ ={bell.œÉ}, i_a={bell.i_a}, and modified Œ∏ = {bell.Œ∏ + bell.m * (1-bell.Œ∏)} after {i} iterations!\")\n",
    "    elif verbose:\n",
    "        print(f\"Converged in {i} iterations.\")\n",
    "        print(f\"Effective k and new c {np.around(bell.grid[bell.index],3),v_greedy[bell.index]}.\")\n",
    "        \n",
    "\n",
    "    return v_greedy[bell.index],v[bell.index]\n",
    "\n",
    "# Obtain Output for Samples\n",
    "class agent:\n",
    "    def __init__(self,\n",
    "                 k,            # current state k_t\n",
    "                 Œ∏,            # perceived shock factor Œ∏\n",
    "                 œÉ,            # risk averseness\n",
    "                 Œ±,            # human capital\n",
    "                 adapt):       # AdapTable \n",
    "        self.k,self.Œ∏, self.œÉ, self.Œ±, self.adapt=k,Œ∏,œÉ,Œ±,adapt\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "# Saltelli\n",
    "SHundth_ResultsN=pd.DataFrame({'Agent':[],'Value':[],'Consumption':[], 'i_a':[], 'm':[]})\n",
    "SHundth_ResultsL=pd.DataFrame({'Agent':[],'Value':[],'Consumption':[], 'i_a':[], 'm':[]})\n",
    "SHundth_ResultsH=pd.DataFrame({'Agent':[],'Value':[],'Consumption':[], 'i_a':[], 'm':[]})\n",
    "for i in range(len(S_sampledf)):#len(S_sampledf)):\n",
    "    info=agent(k=S_sampledf.loc[i,\"k\"], Œ∏=S_sampledf.loc[i,\"Theta\"], œÉ=S_sampledf.loc[i,\"Sigma\"], Œ±=S_sampledf.loc[i,\"Alpha\"],adapt=AdapTableArray)\n",
    "    feasible=which_bellman(info)\n",
    "    if len(feasible)>2:\n",
    "        SHundth_ResultsH.loc[i]=[f\"S{i}\",*feasible[2]]\n",
    "    if len(feasible)>1:\n",
    "        SHundth_ResultsL.loc[i]=[f\"S{i}\",*feasible[1]]\n",
    "    SHundth_ResultsN.loc[i]=[f\"S{i}\",*feasible[0]]\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  N          L          H\n",
      "0     -1.170888e+02 -10.736273 -16.972574\n",
      "1     -6.396648e+01  -7.760943  -6.573503\n",
      "2     -1.105234e+02  -8.622154 -12.347946\n",
      "3     -4.019631e+01 -10.675534 -14.711720\n",
      "4     -3.441186e+01 -10.116293 -15.881917\n",
      "...             ...        ...        ...\n",
      "10235 -2.778606e+01 -12.283369 -11.606918\n",
      "10236 -2.782736e+01  -9.810337  -5.716766\n",
      "10237 -4.013776e+06 -10.754461  -8.779354\n",
      "10238 -2.572163e+01  -6.515430  -3.631795\n",
      "10239 -2.768343e+01  -9.644542  -5.481222\n",
      "\n",
      "[10240 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "print(pd.DataFrame({\"N\":SHundth_ResultsN[\"Value\"], \"L\":SHundth_ResultsL[\"Value\"], \"H\":SHundth_ResultsH[\"Value\"]}))\n",
    "SHundth_ResultsN.to_csv(\"ResultsNone.csv\")\n",
    "SHundth_ResultsL.to_csv(\"ResultsLow.csv\")\n",
    "SHundth_ResultsH.to_csv(\"ResultsHigh.csv\")\n",
    "\n",
    "HundthIndex = pd.DataFrame({\"N\":SHundth_ResultsN[\"Value\"], \"L\":SHundth_ResultsL[\"Value\"], \"H\":SHundth_ResultsH[\"Value\"]}).apply('idxmin', axis=1)\n",
    "HundthCon = pd.DataFrame({\"N\":SHundth_ResultsN[\"Consumption\"], \"L\":SHundth_ResultsL[\"Consumption\"], \"H\":SHundth_ResultsH[\"Consumption\"]})\n",
    "\n",
    "HundthResult = [HundthCon.loc[i, HundthIndex.loc[i]] for i in range(len(HundthIndex))]\n",
    "HundthFinal= pd.DataFrame({\"Equation\":HundthIndex,\"Consumption\": HundthResult})\n",
    "\n",
    "HundthFinal.to_csv(\"ResultsFinal.csv\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BellmanNarrowExtended failed to converge for k=2.4976562500000004, Œ± = 1.1281077012279517,œÉ =-0.2, i_a=0.0, and modified Œ∏ = 0.9 after 3000 iterations!\n",
      "BellmanNarrowExtended failed to converge for k=2.4976562500000004, Œ± = 1.1281077012279517,œÉ =-0.2, i_a=0.25, and modified Œ∏ = 0.95 after 3000 iterations!\n",
      "BellmanNarrowExtended failed to converge for k=2.4976562500000004, Œ± = 1.0421885303013698,œÉ =-0.2, i_a=0.0, and modified Œ∏ = 0.8 after 3000 iterations!\n",
      "BellmanNarrowExtended failed to converge for k=2.4976562500000004, Œ± = 1.0421885303013698,œÉ =-0.2, i_a=0.45, and modified Œ∏ = 0.98 after 3000 iterations!\n",
      "BellmanNarrowExtended failed to converge for k=4.19921875, Œ± = 1.0421885303013698,œÉ =-0.2, i_a=0.0, and modified Œ∏ = 0.9 after 3000 iterations!\n",
      "BellmanNarrowExtended failed to converge for k=4.19921875, Œ± = 1.0421885303013698,œÉ =-0.2, i_a=0.0, and modified Œ∏ = 0.8 after 3000 iterations!\n"
     ]
    }
   ],
   "source": [
    "#Tol 0.001\n",
    "\n",
    "def solve_bellman(bell,\n",
    "                  tol=0.001,\n",
    "                  min_iter=10,\n",
    "                  max_iter=3000,\n",
    "                  verbose=False):\n",
    "    \"\"\"\n",
    "    From: https://python.quantecon.org/optgrowth.html (similar example\n",
    "    https://macroeconomics.github.io/Dynamic%20Programming.html#.ZC13-exBy3I)\n",
    "    \n",
    "    Solve model by iterating with the Bellman operator.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    # Set up loop\n",
    "\n",
    "    v = bell.u(bell.grid,bell.œÉ)  # Initial condition\n",
    "    i = 0\n",
    "    error = tol + 1\n",
    "    max_error = tol*10 + 1\n",
    "\n",
    "    while (i < max_iter and (error > tol or max_error > tol*10)) or (i < min_iter):\n",
    "        v_greedy, v_new = update_bellman(v, bell)\n",
    "        error = np.abs(v[bell.index] - v_new)[bell.index]\n",
    "        max_error = np.max(np.abs(v - v_new))\n",
    "        i += 1\n",
    "        # if verbose and i % print_skip == 0:\n",
    "        #     print(f\"Error at iteration {i} is {error}.\")\n",
    "        v = v_new\n",
    "\n",
    "    if (error > tol) or (max_error > tol*10):\n",
    "        print(f\"{bell.name} failed to converge for k={bell.k}, Œ± = {bell.Œ±},œÉ ={bell.œÉ}, i_a={bell.i_a}, and modified Œ∏ = {bell.Œ∏ + bell.m * (1-bell.Œ∏)} after {i} iterations!\")\n",
    "    elif verbose:\n",
    "        print(f\"Converged in {i} iterations.\")\n",
    "        print(f\"Effective k and new c {np.around(bell.grid[bell.index],3),v_greedy[bell.index]}.\")\n",
    "        \n",
    "\n",
    "    return v_greedy[bell.index],v[bell.index]\n",
    "\n",
    "# Obtain Output for Samples\n",
    "class agent:\n",
    "    def __init__(self,\n",
    "                 k,            # current state k_t\n",
    "                 Œ∏,            # perceived shock factor Œ∏\n",
    "                 œÉ,            # risk averseness\n",
    "                 Œ±,            # human capital\n",
    "                 adapt):       # AdapTable \n",
    "        self.k,self.Œ∏, self.œÉ, self.Œ±, self.adapt=k,Œ∏,œÉ,Œ±,adapt\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "# Saltelli\n",
    "SThouth_ResultsN=pd.DataFrame({'Agent':[],'Value':[],'Consumption':[], 'i_a':[], 'm':[]})\n",
    "SThouth_ResultsL=pd.DataFrame({'Agent':[],'Value':[],'Consumption':[], 'i_a':[], 'm':[]})\n",
    "SThouth_ResultsH=pd.DataFrame({'Agent':[],'Value':[],'Consumption':[], 'i_a':[], 'm':[]})\n",
    "for i in range(len(S_sampledf)):#len(S_sampledf)):\n",
    "    info=agent(k=S_sampledf.loc[i,\"k\"], Œ∏=S_sampledf.loc[i,\"Theta\"], œÉ=S_sampledf.loc[i,\"Sigma\"], Œ±=S_sampledf.loc[i,\"Alpha\"],adapt=AdapTableArray)\n",
    "    feasible=which_bellman(info)\n",
    "    if len(feasible)>2:\n",
    "        SThouth_ResultsH.loc[i]=[f\"S{i}\",*feasible[2]]\n",
    "    if len(feasible)>1:\n",
    "        SThouth_ResultsL.loc[i]=[f\"S{i}\",*feasible[1]]\n",
    "    SThouth_ResultsN.loc[i]=[f\"S{i}\",*feasible[0]]\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 N          L          H\n",
      "0        -3.408028  -7.552071 -10.840466\n",
      "1         1.081112  -1.289895  -2.818717\n",
      "2        -3.103145  -7.074379 -10.142249\n",
      "3        -3.197720  -7.069757 -10.026376\n",
      "4   -169591.717026 -11.643219 -19.646231\n",
      "..             ...        ...        ...\n",
      "495      -0.492900  -1.473721   0.166545\n",
      "496      -2.007701  -2.915935  -2.061192\n",
      "497      -2.227449  -2.975682  -1.886542\n",
      "498     -82.332318  -6.233959  -4.393053\n",
      "499      -1.814389  -2.668771  -1.712757\n",
      "\n",
      "[500 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "print(pd.DataFrame({\"N\":SThouth_ResultsN[\"Value\"], \"L\":SThouth_ResultsL[\"Value\"], \"H\":SThouth_ResultsH[\"Value\"]}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tol 0.1 just Plus 10 on the grid\n",
    "\n",
    "\n",
    "class BellmanEquation:\n",
    "     #Adapted from: https://python.quantecon.org/optgrowth.html\n",
    "    def __init__(self,\n",
    "                 u,            # utility function\n",
    "                 f,            # production function\n",
    "                 k,            # current state k_t\n",
    "                 Œ∏,            # given shock factor Œ∏\n",
    "                 œÉ,            # risk averseness\n",
    "                 Œ±,            # human capital\n",
    "                 i_a,          # adaptation investment\n",
    "                 m,            # protection multiplier\n",
    "                 Œ≤=Œ≤,          # discount factor\n",
    "                 ùõø=ùõø,          # depreciation factor \n",
    "                 name=\"BellmanNarrowExtended\"):\n",
    "\n",
    "        self.u, self.f, self.k, self.Œ≤, self.Œ∏, self.ùõø, self.œÉ, self.Œ±, self.i_a, self.m, self.name = u, f, k, Œ≤, Œ∏, ùõø, œÉ, Œ±, i_a, m, name\n",
    "\n",
    "        # Set up grid\n",
    "        \n",
    "        startgrid=np.array([1.0e-7,1,2,3,4,5,6,7,8,9,10,k+10])\n",
    "\n",
    "        ind=np.searchsorted(startgrid, k)\n",
    "        self.grid=np.concatenate((startgrid[:ind],np.array([k*0.99999, k]),\n",
    "                                 startgrid[ind:]))\n",
    "\n",
    "        self.grid=self.grid[self.grid>i_a]\n",
    "\n",
    "        # Identify target state k\n",
    "        self.index = np.searchsorted(self.grid, k)-1\n",
    "    \n",
    "    def value(self, c, y, v_array):\n",
    "        \"\"\"\n",
    "        Right hand side of the Bellman equation.\n",
    "        \"\"\"\n",
    "\n",
    "        u, f, Œ≤, Œ∏, ùõø, œÉ, Œ±, i_a, m = self.u, self.f, self.Œ≤, self.Œ∏, self.ùõø, self.œÉ, self.Œ±, self.i_a, self.m\n",
    "\n",
    "        v = interp1d(self.grid, v_array, bounds_error=False, \n",
    "                     fill_value=\"extrapolate\")\n",
    "        \n",
    "        return u(c,œÉ) + Œ≤ * v((Œ∏ + m * (1-Œ∏)) * (f(y,Œ±) - c - i_a + (1 - ùõø) * y))\n",
    "\n",
    "\n",
    "\n",
    "def update_bellman(v, bell):\n",
    "    \"\"\"\n",
    "    From: https://python.quantecon.org/optgrowth.html (similar example\n",
    "    https://macroeconomics.github.io/Dynamic%20Programming.html#.ZC13-exBy3I)\n",
    "    \n",
    "    The Bellman operator.  Updates the guess of the value function\n",
    "    and also computes a v-greedy policy.\n",
    "\n",
    "      * bell is an instance of Bellman equation\n",
    "      * v is an array representing a guess of the value function\n",
    "\n",
    "    \"\"\"\n",
    "    v_new = np.empty_like(v)\n",
    "    v_greedy = np.empty_like(v)\n",
    "    \n",
    "    for i in range(len(bell.grid)):\n",
    "        y = bell.grid[i]\n",
    "        # Maximize RHS of Bellman equation at state y\n",
    "        \n",
    "        c_star, v_max = maximize(bell.value, min([1e-8,y*0.00001]), \n",
    "                                 y-bell.i_a, (y, v))\n",
    "        #VMG HELP! can anyone check that (1) subtracting i_a and \n",
    "        # (2) omitting any grid values less than i_a \n",
    "        # will not be problematic? The only thing I can come up with\n",
    "        # is if i_a is greater than k*0.99999\n",
    "        # which_bellman() now accounts for that case. Whole thing \n",
    "        # could use refinement.\n",
    "      \n",
    "        v_new[i] = v_max\n",
    "        v_greedy[i] = c_star\n",
    "\n",
    "    return v_greedy, v_new\n",
    "\n",
    "def which_bellman(agentinfo):\n",
    "    \"\"\"\n",
    "    Solves bellman for each affordable adaptation option.\n",
    "    \"\"\"\n",
    "    feasible=[]\n",
    "\n",
    "\n",
    "    for option in agentinfo.adapt:\n",
    "        if option[1]>=(income_function(agentinfo.k,agentinfo.Œ±)+(1-ùõø)*agentinfo.k)*0.99998:\n",
    "            # ensures that the gridpoint\n",
    "            # just below income, income*0.99999, is included\n",
    "            pass\n",
    "        else:\n",
    "            #print(f'working theta = {agentinfo.Œ∏ + option[0] *\\\n",
    "            #  (1-agentinfo.Œ∏)}, i_a= {option[1]}, k= {agentinfo.k}')\n",
    "            c,v=solve_bellman(BellmanEquation(u=utility, \n",
    "                              f=income_function, k=agentinfo.k, \n",
    "                              Œ∏=agentinfo.Œ∏, œÉ=agentinfo.œÉ, \n",
    "                              Œ±=agentinfo.Œ±, i_a=option[1],m=option[0]))\n",
    "            feasible.append([v,c,option[1],option[0]])\n",
    "\n",
    "    best=min(feasible)\n",
    "\n",
    "    \n",
    "    return feasible\n",
    "\n",
    "\n",
    "\n",
    "def solve_bellman(bell,\n",
    "                  tol=0.1,\n",
    "                  min_iter=10,\n",
    "                  max_iter=1000,\n",
    "                  verbose=False):\n",
    "    \"\"\"\n",
    "    From: https://python.quantecon.org/optgrowth.html (similar example\n",
    "    https://macroeconomics.github.io/Dynamic%20Programming.html#.ZC13-exBy3I)\n",
    "    \n",
    "    Solve model by iterating with the Bellman operator.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    # Set up loop\n",
    "\n",
    "    v = bell.u(bell.grid,bell.œÉ)  # Initial condition\n",
    "    i = 0\n",
    "    error = tol + 1\n",
    "    max_error = tol*10 + 1\n",
    "\n",
    "    while (i < max_iter and (error > tol or max_error > tol*10)) or (i < min_iter):\n",
    "        v_greedy, v_new = update_bellman(v, bell)\n",
    "        error = np.abs(v[bell.index] - v_new)[bell.index]\n",
    "        max_error = np.max(np.abs(v - v_new))\n",
    "        i += 1\n",
    "        # if verbose and i % print_skip == 0:\n",
    "        #     print(f\"Error at iteration {i} is {error}.\")\n",
    "        v = v_new\n",
    "\n",
    "    if (error > tol) or (max_error > tol*10):\n",
    "        print(f\"{bell.name} failed to converge for k={bell.k}, Œ± = {bell.Œ±},œÉ ={bell.œÉ}, i_a={bell.i_a}, and modified Œ∏ = {bell.Œ∏ + bell.m * (1-bell.Œ∏)} after {i} iterations!\")\n",
    "    elif verbose:\n",
    "        print(f\"Converged in {i} iterations.\")\n",
    "        print(f\"Effective k and new c {np.around(bell.grid[bell.index],3),v_greedy[bell.index]}.\")\n",
    "        \n",
    "\n",
    "    return v_greedy[bell.index],v[bell.index]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Obtain Output for Samples\n",
    "class agent:\n",
    "    def __init__(self,\n",
    "                 k,            # current state k_t\n",
    "                 Œ∏,            # perceived shock factor Œ∏\n",
    "                 œÉ,            # risk averseness\n",
    "                 Œ±,            # human capital\n",
    "                 adapt):       # AdapTable \n",
    "        self.k,self.Œ∏, self.œÉ, self.Œ±, self.adapt=k,Œ∏,œÉ,Œ±,adapt\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "# Saltelli\n",
    "SGrid10_ResultsN=pd.DataFrame({'Agent':[],'Value':[],'Consumption':[], 'i_a':[], 'm':[]})\n",
    "SGrid10_ResultsL=pd.DataFrame({'Agent':[],'Value':[],'Consumption':[], 'i_a':[], 'm':[]})\n",
    "SGrid10_ResultsH=pd.DataFrame({'Agent':[],'Value':[],'Consumption':[], 'i_a':[], 'm':[]})\n",
    "for i in range(len(S_sampledf)):#len(S_sampledf)):\n",
    "    info=agent(k=S_sampledf.loc[i,\"k\"], Œ∏=S_sampledf.loc[i,\"Theta\"], œÉ=S_sampledf.loc[i,\"Sigma\"], Œ±=S_sampledf.loc[i,\"Alpha\"],adapt=AdapTableArray)\n",
    "    feasible=which_bellman(info)\n",
    "    if len(feasible)>2:\n",
    "        SGrid10_ResultsH.loc[i]=[f\"S{i}\",*feasible[2]]\n",
    "    if len(feasible)>1:\n",
    "        SGrid10_ResultsL.loc[i]=[f\"S{i}\",*feasible[1]]\n",
    "    SGrid10_ResultsN.loc[i]=[f\"S{i}\",*feasible[0]]\n",
    " \n",
    "\n",
    " \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 N         L          H\n",
      "0        -3.406300 -5.701979  -8.987846\n",
      "1         1.081514  0.798566  -0.976655\n",
      "2        -3.101417 -5.224954  -8.290181\n",
      "3        -3.127967 -5.226291  -8.156691\n",
      "4   -169589.913333 -9.786140 -16.005159\n",
      "..             ...       ...        ...\n",
      "495       0.292817  0.416264   2.027577\n",
      "496      -1.010402 -1.092142  -0.257316\n",
      "497      -1.994235 -1.068638  -0.023402\n",
      "498     -80.513513 -4.421133  -2.536916\n",
      "499      -0.817090 -0.845174   0.090783\n",
      "\n",
      "[500 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "print(pd.DataFrame({\"N\":SGrid10_ResultsN[\"Value\"], \"L\":SGrid10_ResultsL[\"Value\"], \"H\":SGrid10_ResultsH[\"Value\"]}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Hund      Thou\n",
      "0    0.721988  0.721987\n",
      "1    0.906963  0.906383\n",
      "2    0.788278  0.788278\n",
      "3    0.741651  0.741651\n",
      "4    0.006341  0.006341\n",
      "..        ...       ...\n",
      "495  2.217495  2.217494\n",
      "496  2.062920  2.062910\n",
      "497  2.028719  2.028695\n",
      "498  1.376168  1.376160\n",
      "499  2.266383  2.266372\n",
      "\n",
      "[500 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "HundthIndex = pd.DataFrame({\"N\":SHundth_ResultsN[\"Value\"], \"L\":SHundth_ResultsL[\"Value\"], \"H\":SHundth_ResultsH[\"Value\"]}).apply('idxmin', axis=1)\n",
    "TenthIndex = pd.DataFrame({\"N\":STenth_ResultsN[\"Value\"], \"L\":STenth_ResultsL[\"Value\"], \"H\":STenth_ResultsH[\"Value\"]}).apply('idxmin', axis=1)\n",
    "ThouthIndex = pd.DataFrame({\"N\":SThouth_ResultsN[\"Value\"], \"L\":SThouth_ResultsL[\"Value\"], \"H\":SThouth_ResultsH[\"Value\"]}).apply('idxmin', axis=1)\n",
    "HundthCon = pd.DataFrame({\"N\":SHundth_ResultsN[\"Consumption\"], \"L\":SHundth_ResultsL[\"Consumption\"], \"H\":SHundth_ResultsH[\"Consumption\"]})\n",
    "TenthCon = pd.DataFrame({\"N\":STenth_ResultsN[\"Consumption\"], \"L\":STenth_ResultsL[\"Consumption\"], \"H\":STenth_ResultsH[\"Consumption\"]})\n",
    "ThouthCon = pd.DataFrame({\"N\":SThouth_ResultsN[\"Consumption\"], \"L\":SThouth_ResultsL[\"Consumption\"], \"H\":SThouth_ResultsH[\"Consumption\"]})\n",
    "\n",
    "HundthResult = [HundthCon.loc[i, HundthIndex.loc[i]] for i in range(len(HundthIndex))]\n",
    "ThouthResult = [ThouthCon.loc[i, ThouthIndex.loc[i]] for i in range(len(ThouthIndex))]\n",
    "print(pd.DataFrame({\"Hund\":HundthResult,\"Thou\":ThouthResult}))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "# LHS\n",
    "LH_ResultsN=pd.DataFrame({'Agent':[],'Value':[],'Consumption':[], 'i_a':[], 'm':[]})\n",
    "LH_ResultsL=pd.DataFrame({'Agent':[],'Value':[],'Consumption':[], 'i_a':[], 'm':[]})\n",
    "LH_ResultsH=pd.DataFrame({'Agent':[],'Value':[],'Consumption':[], 'i_a':[], 'm':[]})\n",
    "for i in range(len(LH_sampledf)):\n",
    "    info=agent(k=LH_sampledf.loc[i,\"k\"], Œ∏=LH_sampledf.loc[i,\"Theta\"], œÉ=LH_sampledf.loc[i,\"Sigma\"], Œ±=LH_sampledf.loc[i,\"Alpha\"],adapt=AdapTableArray)\n",
    "    feasible=which_bellman(info)\n",
    "    if len(feasible)>2:\n",
    "        LH_ResultsH.loc[i]=[f\"S{i}\",*feasible[2]]\n",
    "    if len(feasible)>1:\n",
    "        LH_ResultsL.loc[i]=[f\"S{i}\",*feasible[1]]\n",
    "    LH_ResultsN.loc[i]=[f\"S{i}\",*feasible[0]]\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Random\n",
    "\n",
    "R_ResultsN=pd.DataFrame({'Agent':[],'Value':[],'Consumption':[], 'i_a':[], 'm':[]})\n",
    "R_ResultsL=pd.DataFrame({'Agent':[],'Value':[],'Consumption':[], 'i_a':[], 'm':[]})\n",
    "R_ResultsH=pd.DataFrame({'Agent':[],'Value':[],'Consumption':[], 'i_a':[], 'm':[]})\n",
    "for i in range(len(R_sampledf)):\n",
    "    info=agent(k=R_sampledf.loc[i,\"k\"], Œ∏=R_sampledf.loc[i,\"Theta\"], œÉ=R_sampledf.loc[i,\"Sigma\"], Œ±=R_sampledf.loc[i,\"Alpha\"], adapt=AdapTableArray)\n",
    "    feasible=which_bellman(info)\n",
    "    if len(feasible)>2:\n",
    "        R_ResultsH.loc[i]=[f\"S{i}\",*feasible[2]]\n",
    "    if len(feasible)>1:\n",
    "        R_ResultsL.loc[i]=[f\"S{i}\",*feasible[1]]\n",
    "    R_ResultsN.loc[i]=[f\"S{i}\",*feasible[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "S_ResultsN.to_csv(f\"SaltelliResultsNone.csv\")\n",
    "S_ResultsL.to_csv(f\"SaltelliResultsLow.csv\")\n",
    "S_ResultsH.to_csv(f\"SaltelliResultsHigh.csv\")\n",
    "\n",
    "# LH_ResultsN.to_csv(f\"LatinResultsNone.csv\")\n",
    "# LH_ResultsL.to_csv(f\"LatinResultsLow.csv\")\n",
    "# LH_ResultsH.to_csv(f\"LatinResultsHigh.csv\")\n",
    "\n",
    "# R_ResultsN.to_csv(f\"RandomResultsNone.csv\")\n",
    "# R_ResultsL.to_csv(f\"RandomResultsLow.csv\")\n",
    "# R_ResultsH.to_csv(f\"RandomResultsHigh.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Interpolated Surface (Linear)\n",
    "print(len(S_sampledf[\"k\"]),len(S_ResultsN[\"Value\"]))\n",
    "# Saltelli\n",
    "S_N_Interp_C=griddata((S_sampledf[\"k\"],S_sampledf[\"Theta\"], S_sampledf[\"Sigma\"],S_sampledf[\"Alpha\"]),S_ResultsN[\"Consumption\"],(R_sampledf[\"k\"],R_sampledf[\"Theta\"], R_sampledf[\"Sigma\"],R_sampledf[\"Alpha\"]), method='linear')\n",
    "S_N_Interp_V=griddata((S_sampledf[\"k\"],S_sampledf[\"Theta\"], S_sampledf[\"Sigma\"],S_sampledf[\"Alpha\"]),S_ResultsN[\"Value\"],(R_sampledf[\"k\"],R_sampledf[\"Theta\"], R_sampledf[\"Sigma\"],R_sampledf[\"Alpha\"]), method='linear')\n",
    "\n",
    "S_L_Interp_C=griddata((S_sampledf[\"k\"],S_sampledf[\"Theta\"], S_sampledf[\"Sigma\"],S_sampledf[\"Alpha\"]),S_ResultsL[\"Consumption\"],(R_sampledf[\"k\"],R_sampledf[\"Theta\"], R_sampledf[\"Sigma\"],R_sampledf[\"Alpha\"]), method='linear')\n",
    "S_L_Interp_V=griddata((S_sampledf[\"k\"],S_sampledf[\"Theta\"], S_sampledf[\"Sigma\"],S_sampledf[\"Alpha\"]),S_ResultsL[\"Value\"],(R_sampledf[\"k\"],R_sampledf[\"Theta\"], R_sampledf[\"Sigma\"],R_sampledf[\"Alpha\"]), method='linear')\n",
    "\n",
    "S_H_Interp_C=griddata((S_sampledf[\"k\"],S_sampledf[\"Theta\"], S_sampledf[\"Sigma\"],S_sampledf[\"Alpha\"]),S_ResultsH[\"Consumption\"],(R_sampledf[\"k\"],R_sampledf[\"Theta\"], R_sampledf[\"Sigma\"],R_sampledf[\"Alpha\"]), method='linear')\n",
    "S_H_Interp_V=griddata((S_sampledf[\"k\"],S_sampledf[\"Theta\"], S_sampledf[\"Sigma\"],S_sampledf[\"Alpha\"]),S_ResultsH[\"Value\"],(R_sampledf[\"k\"],R_sampledf[\"Theta\"], R_sampledf[\"Sigma\"],R_sampledf[\"Alpha\"]), method='linear')\n",
    "\n",
    "# LHS\n",
    "LH_N_Interp=griddata((LH_sampledf[\"k\"],LH_sampledf[\"Theta\"], LH_sampledf[\"Sigma\"],LH_sampledf[\"Alpha\"]),LH_ResultsN[\"Consumption\"],(R_sampledf[\"k\"],R_sampledf[\"Theta\"], R_sampledf[\"Sigma\"],R_sampledf[\"Alpha\"]), method='linear')\n",
    "LH_N_Interp=griddata((LH_sampledf[\"k\"],LH_sampledf[\"Theta\"], LH_sampledf[\"Sigma\"],LH_sampledf[\"Alpha\"]),LH_ResultsN[\"Value\"],(R_sampledf[\"k\"],R_sampledf[\"Theta\"], R_sampledf[\"Sigma\"],R_sampledf[\"Alpha\"]), method='linear')\n",
    "\n",
    "LH_L_Interp=griddata((LH_sampledf[\"k\"],LH_sampledf[\"Theta\"], LH_sampledf[\"Sigma\"],LH_sampledf[\"Alpha\"]),LH_ResultsL[\"Consumption\"],(R_sampledf[\"k\"],R_sampledf[\"Theta\"], R_sampledf[\"Sigma\"],R_sampledf[\"Alpha\"]), method='linear')\n",
    "LH_L_Interp=griddata((LH_sampledf[\"k\"],LH_sampledf[\"Theta\"], LH_sampledf[\"Sigma\"],LH_sampledf[\"Alpha\"]),LH_ResultsL[\"Value\"],(R_sampledf[\"k\"],R_sampledf[\"Theta\"], R_sampledf[\"Sigma\"],R_sampledf[\"Alpha\"]), method='linear')\n",
    "\n",
    "LH_H_Interp=griddata((LH_sampledf[\"k\"],LH_sampledf[\"Theta\"], LH_sampledf[\"Sigma\"],LH_sampledf[\"Alpha\"]),LH_ResultsH[\"Consumption\"],(R_sampledf[\"k\"],R_sampledf[\"Theta\"], R_sampledf[\"Sigma\"],R_sampledf[\"Alpha\"]), method='linear')\n",
    "LH_H_Interp=griddata((LH_sampledf[\"k\"],LH_sampledf[\"Theta\"], LH_sampledf[\"Sigma\"],LH_sampledf[\"Alpha\"]),LH_ResultsH[\"Value\"],(R_sampledf[\"k\"],R_sampledf[\"Theta\"], R_sampledf[\"Sigma\"],R_sampledf[\"Alpha\"]), method='linear')\n",
    "\n",
    "\n",
    "# Both, bc why not?\n",
    "SLH_N_Interp=griddata((pd.concat([S_sampledf[\"k\"],LH_sampledf[\"k\"]]),pd.concat([S_sampledf[\"Theta\"],LH_sampledf[\"Theta\"]]), pd.concat([S_sampledf[\"Sigma\"],LH_sampledf[\"Sigma\"]]),pd.concat([S_sampledf[\"Alpha\"],LH_sampledf[\"Alpha\"]])),pd.concat([S_ResultsN[\"Consumption\"],LH_ResultsN[\"Consumption\"]]),(R_sampledf[\"k\"],R_sampledf[\"Theta\"], R_sampledf[\"Sigma\"],R_sampledf[\"Alpha\"]), method='linear')\n",
    "SLH_N_Interp=griddata((pd.concat([S_sampledf[\"k\"],LH_sampledf[\"k\"]]),pd.concat([S_sampledf[\"Theta\"],LH_sampledf[\"Theta\"]]), pd.concat([S_sampledf[\"Sigma\"],LH_sampledf[\"Sigma\"]]),pd.concat([S_sampledf[\"Alpha\"],LH_sampledf[\"Alpha\"]])),pd.concat([S_ResultsN[\"Value\"],LH_ResultsN[\"Value\"]]),(R_sampledf[\"k\"],R_sampledf[\"Theta\"], R_sampledf[\"Sigma\"],R_sampledf[\"Alpha\"]), method='linear')\n",
    "\n",
    "SLH_L_Interp=griddata((pd.concat([S_sampledf[\"k\"],LH_sampledf[\"k\"]]),pd.concat([S_sampledf[\"Theta\"],LH_sampledf[\"Theta\"]]), pd.concat([S_sampledf[\"Sigma\"],LH_sampledf[\"Sigma\"]]),pd.concat([S_sampledf[\"Alpha\"],LH_sampledf[\"Alpha\"]])),pd.concat([S_ResultsN[\"Consumption\"],LH_ResultsN[\"Consumption\"]]),(R_sampledf[\"k\"],R_sampledf[\"Theta\"], R_sampledf[\"Sigma\"],R_sampledf[\"Alpha\"]), method='linear')\n",
    "SLH_L_Interp=griddata((pd.concat([S_sampledf[\"k\"],LH_sampledf[\"k\"]]),pd.concat([S_sampledf[\"Theta\"],LH_sampledf[\"Theta\"]]), pd.concat([S_sampledf[\"Sigma\"],LH_sampledf[\"Sigma\"]]),pd.concat([S_sampledf[\"Alpha\"],LH_sampledf[\"Alpha\"]])),pd.concat([S_ResultsN[\"Value\"],LH_ResultsN[\"Value\"]]),(R_sampledf[\"k\"],R_sampledf[\"Theta\"], R_sampledf[\"Sigma\"],R_sampledf[\"Alpha\"]), method='linear')\n",
    "\n",
    "SLH_H_Interp=griddata((pd.concat([S_sampledf[\"k\"],LH_sampledf[\"k\"]]),pd.concat([S_sampledf[\"Theta\"],LH_sampledf[\"Theta\"]]), pd.concat([S_sampledf[\"Sigma\"],LH_sampledf[\"Sigma\"]]),pd.concat([S_sampledf[\"Alpha\"],LH_sampledf[\"Alpha\"]])),pd.concat([S_ResultsN[\"Consumption\"],LH_ResultsN[\"Consumption\"]]),(R_sampledf[\"k\"],R_sampledf[\"Theta\"], R_sampledf[\"Sigma\"],R_sampledf[\"Alpha\"]), method='linear')\n",
    "SLH_H_Interp=griddata((pd.concat([S_sampledf[\"k\"],LH_sampledf[\"k\"]]),pd.concat([S_sampledf[\"Theta\"],LH_sampledf[\"Theta\"]]), pd.concat([S_sampledf[\"Sigma\"],LH_sampledf[\"Sigma\"]]),pd.concat([S_sampledf[\"Alpha\"],LH_sampledf[\"Alpha\"]])),pd.concat([S_ResultsN[\"Value\"],LH_ResultsN[\"Value\"]]),(R_sampledf[\"k\"],R_sampledf[\"Theta\"], R_sampledf[\"Sigma\"],R_sampledf[\"Alpha\"]), method='linear')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Interpolated Surface (Nearest)\n",
    "print(len(S_sampledf[\"k\"]),len(S_ResultsN[\"Value\"]))\n",
    "# Saltelli\n",
    "S_N_Interp_C=griddata((S_sampledf[\"k\"],S_sampledf[\"Theta\"], S_sampledf[\"Sigma\"],S_sampledf[\"Alpha\"]),S_ResultsN[\"Consumption\"],(R_sampledf[\"k\"],R_sampledf[\"Theta\"], R_sampledf[\"Sigma\"],R_sampledf[\"Alpha\"]), method='nearest')\n",
    "S_N_Interp_V=griddata((S_sampledf[\"k\"],S_sampledf[\"Theta\"], S_sampledf[\"Sigma\"],S_sampledf[\"Alpha\"]),S_ResultsN[\"Value\"],(R_sampledf[\"k\"],R_sampledf[\"Theta\"], R_sampledf[\"Sigma\"],R_sampledf[\"Alpha\"]), method='nearest')\n",
    "\n",
    "S_L_Interp_C=griddata((S_sampledf[\"k\"],S_sampledf[\"Theta\"], S_sampledf[\"Sigma\"],S_sampledf[\"Alpha\"]),S_ResultsL[\"Consumption\"],(R_sampledf[\"k\"],R_sampledf[\"Theta\"], R_sampledf[\"Sigma\"],R_sampledf[\"Alpha\"]), method='nearest')\n",
    "S_L_Interp_V=griddata((S_sampledf[\"k\"],S_sampledf[\"Theta\"], S_sampledf[\"Sigma\"],S_sampledf[\"Alpha\"]),S_ResultsL[\"Value\"],(R_sampledf[\"k\"],R_sampledf[\"Theta\"], R_sampledf[\"Sigma\"],R_sampledf[\"Alpha\"]), method='nearest')\n",
    "\n",
    "S_H_Interp_C=griddata((S_sampledf[\"k\"],S_sampledf[\"Theta\"], S_sampledf[\"Sigma\"],S_sampledf[\"Alpha\"]),S_ResultsH[\"Consumption\"],(R_sampledf[\"k\"],R_sampledf[\"Theta\"], R_sampledf[\"Sigma\"],R_sampledf[\"Alpha\"]), method='nearest')\n",
    "S_H_Interp_V=griddata((S_sampledf[\"k\"],S_sampledf[\"Theta\"], S_sampledf[\"Sigma\"],S_sampledf[\"Alpha\"]),S_ResultsH[\"Value\"],(R_sampledf[\"k\"],R_sampledf[\"Theta\"], R_sampledf[\"Sigma\"],R_sampledf[\"Alpha\"]), method='nearest')\n",
    "\n",
    "# LHS\n",
    "LH_N_Interp_C=griddata((LH_sampledf[\"k\"],LH_sampledf[\"Theta\"], LH_sampledf[\"Sigma\"],LH_sampledf[\"Alpha\"]),LH_ResultsN[\"Consumption\"],(R_sampledf[\"k\"],R_sampledf[\"Theta\"], R_sampledf[\"Sigma\"],R_sampledf[\"Alpha\"]), method='nearest')\n",
    "LH_N_Interp_V=griddata((LH_sampledf[\"k\"],LH_sampledf[\"Theta\"], LH_sampledf[\"Sigma\"],LH_sampledf[\"Alpha\"]),LH_ResultsN[\"Value\"],(R_sampledf[\"k\"],R_sampledf[\"Theta\"], R_sampledf[\"Sigma\"],R_sampledf[\"Alpha\"]), method='nearest')\n",
    "\n",
    "LH_L_Interp_C=griddata((LH_sampledf[\"k\"],LH_sampledf[\"Theta\"], LH_sampledf[\"Sigma\"],LH_sampledf[\"Alpha\"]),LH_ResultsL[\"Consumption\"],(R_sampledf[\"k\"],R_sampledf[\"Theta\"], R_sampledf[\"Sigma\"],R_sampledf[\"Alpha\"]), method='nearest')\n",
    "LH_L_Interp_V=griddata((LH_sampledf[\"k\"],LH_sampledf[\"Theta\"], LH_sampledf[\"Sigma\"],LH_sampledf[\"Alpha\"]),LH_ResultsL[\"Value\"],(R_sampledf[\"k\"],R_sampledf[\"Theta\"], R_sampledf[\"Sigma\"],R_sampledf[\"Alpha\"]), method='nearest')\n",
    "\n",
    "LH_H_Interp_C=griddata((LH_sampledf[\"k\"],LH_sampledf[\"Theta\"], LH_sampledf[\"Sigma\"],LH_sampledf[\"Alpha\"]),LH_ResultsH[\"Consumption\"],(R_sampledf[\"k\"],R_sampledf[\"Theta\"], R_sampledf[\"Sigma\"],R_sampledf[\"Alpha\"]), method='nearest')\n",
    "LH_H_Interp_V=griddata((LH_sampledf[\"k\"],LH_sampledf[\"Theta\"], LH_sampledf[\"Sigma\"],LH_sampledf[\"Alpha\"]),LH_ResultsH[\"Value\"],(R_sampledf[\"k\"],R_sampledf[\"Theta\"], R_sampledf[\"Sigma\"],R_sampledf[\"Alpha\"]), method='nearest')\n",
    "\n",
    "\n",
    "# Both, bc why not?\n",
    "SLH_N_Interp_C=griddata((pd.concat([S_sampledf[\"k\"],LH_sampledf[\"k\"]]),pd.concat([S_sampledf[\"Theta\"],LH_sampledf[\"Theta\"]]), pd.concat([S_sampledf[\"Sigma\"],LH_sampledf[\"Sigma\"]]),pd.concat([S_sampledf[\"Alpha\"],LH_sampledf[\"Alpha\"]])),pd.concat([S_ResultsN[\"Consumption\"],LH_ResultsN[\"Consumption\"]]),(R_sampledf[\"k\"],R_sampledf[\"Theta\"], R_sampledf[\"Sigma\"],R_sampledf[\"Alpha\"]), method='nearest')\n",
    "SLH_N_Interp_V=griddata((pd.concat([S_sampledf[\"k\"],LH_sampledf[\"k\"]]),pd.concat([S_sampledf[\"Theta\"],LH_sampledf[\"Theta\"]]), pd.concat([S_sampledf[\"Sigma\"],LH_sampledf[\"Sigma\"]]),pd.concat([S_sampledf[\"Alpha\"],LH_sampledf[\"Alpha\"]])),pd.concat([S_ResultsN[\"Value\"],LH_ResultsN[\"Value\"]]),(R_sampledf[\"k\"],R_sampledf[\"Theta\"], R_sampledf[\"Sigma\"],R_sampledf[\"Alpha\"]), method='nearest')\n",
    "\n",
    "SLH_L_Interp_C=griddata((pd.concat([S_sampledf[\"k\"],LH_sampledf[\"k\"]]),pd.concat([S_sampledf[\"Theta\"],LH_sampledf[\"Theta\"]]), pd.concat([S_sampledf[\"Sigma\"],LH_sampledf[\"Sigma\"]]),pd.concat([S_sampledf[\"Alpha\"],LH_sampledf[\"Alpha\"]])),pd.concat([S_ResultsN[\"Consumption\"],LH_ResultsN[\"Consumption\"]]),(R_sampledf[\"k\"],R_sampledf[\"Theta\"], R_sampledf[\"Sigma\"],R_sampledf[\"Alpha\"]), method='nearest')\n",
    "SLH_L_Interp_V=griddata((pd.concat([S_sampledf[\"k\"],LH_sampledf[\"k\"]]),pd.concat([S_sampledf[\"Theta\"],LH_sampledf[\"Theta\"]]), pd.concat([S_sampledf[\"Sigma\"],LH_sampledf[\"Sigma\"]]),pd.concat([S_sampledf[\"Alpha\"],LH_sampledf[\"Alpha\"]])),pd.concat([S_ResultsN[\"Value\"],LH_ResultsN[\"Value\"]]),(R_sampledf[\"k\"],R_sampledf[\"Theta\"], R_sampledf[\"Sigma\"],R_sampledf[\"Alpha\"]), method='nearest')\n",
    "\n",
    "SLH_H_Interp_C=griddata((pd.concat([S_sampledf[\"k\"],LH_sampledf[\"k\"]]),pd.concat([S_sampledf[\"Theta\"],LH_sampledf[\"Theta\"]]), pd.concat([S_sampledf[\"Sigma\"],LH_sampledf[\"Sigma\"]]),pd.concat([S_sampledf[\"Alpha\"],LH_sampledf[\"Alpha\"]])),pd.concat([S_ResultsN[\"Consumption\"],LH_ResultsN[\"Consumption\"]]),(R_sampledf[\"k\"],R_sampledf[\"Theta\"], R_sampledf[\"Sigma\"],R_sampledf[\"Alpha\"]), method='nearest')\n",
    "SLH_H_Interp_V=griddata((pd.concat([S_sampledf[\"k\"],LH_sampledf[\"k\"]]),pd.concat([S_sampledf[\"Theta\"],LH_sampledf[\"Theta\"]]), pd.concat([S_sampledf[\"Sigma\"],LH_sampledf[\"Sigma\"]]),pd.concat([S_sampledf[\"Alpha\"],LH_sampledf[\"Alpha\"]])),pd.concat([S_ResultsN[\"Value\"],LH_ResultsN[\"Value\"]]),(R_sampledf[\"k\"],R_sampledf[\"Theta\"], R_sampledf[\"Sigma\"],R_sampledf[\"Alpha\"]), method='nearest')\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "S_Interp_V=torch.stack([torch.tensor(S_N_Interp_V),torch.tensor(S_L_Interp_V),torch.tensor(S_H_Interp_V)], dim=1)\n",
    "S_Interp_C=torch.stack([torch.tensor(S_N_Interp_C),torch.tensor(S_L_Interp_C),torch.tensor(S_H_Interp_C)], dim=1)\n",
    "S_Interp_max=torch.max(S_Interp_V,dim=1)\n",
    "\n",
    "S_consumption=S_Interp_C*torch.nn.functional.one_hot(S_Interp_max[1])\n",
    "S_consumption=S_consumption.sum(dim=1)\n",
    "\n",
    "S_adaptation=S_Interp_max[0]\n",
    "\n",
    "print(S_Interp_V)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LH_Interp_V=torch.stack([torch.tensor(LH_N_Interp_V),torch.tensor(LH_L_Interp_V),torch.tensor(LH_H_Interp_V)], dim=1)\n",
    "LH_Interp_C=torch.stack([torch.tensor(LH_N_Interp_C),torch.tensor(LH_L_Interp_C),torch.tensor(LH_H_Interp_C)], dim=1)\n",
    "LH_Interp_max=torch.max(LH_Interp_V,dim=1)\n",
    "\n",
    "LH_consumption=LH_Interp_C*torch.nn.functional.one_hot(LH_Interp_max[1])\n",
    "LH_consumption=LH_consumption.sum(dim=1)\n",
    "\n",
    "LH_adaptation=LH_Interp_max[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SLH_Interp_V=torch.stack([torch.tensor(SLH_N_Interp_V),torch.tensor(SLH_L_Interp_V),torch.tensor(SLH_H_Interp_V)], dim=1)\n",
    "SLH_Interp_C=torch.stack([torch.tensor(SLH_N_Interp_C),torch.tensor(SLH_L_Interp_C),torch.tensor(SLH_H_Interp_C)], dim=1)\n",
    "SLH_Interp_max=torch.max(SLH_Interp_V,dim=1)\n",
    "\n",
    "SLH_consumption=SLH_Interp_C*torch.nn.functional.one_hot(SLH_Interp_max[1])\n",
    "SLH_consumption=SLH_consumption.sum(dim=1)\n",
    "\n",
    "SLH_adaptation=SLH_Interp_max[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Excluded Sample \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.scatter(x=R_sampledf.loc[0:99,'k'], y=S_N_Interp, c='blue', s=5, alpha=0.3)\n",
    "plt.scatter(x=R_sampledf.loc[0:99,'k'], y=R_ResultsN['Consumption'], c='black', s=1)\n",
    "plt.ylabel(\"Consumption\")\n",
    "plt.xlabel(\"k\")\n",
    "\n",
    "plt.show()\n",
    "\n",
    "\n",
    "plt.scatter(x=R_sampledf.loc[0:99,'k'], y=S_N_Interp, c=range(100), s=7, alpha=0.3)\n",
    "plt.scatter(x=R_sampledf.loc[0:99,'k'], y=R_ResultsN['Consumption'], c=range(100), s=1)\n",
    "plt.xlabel(\"k\")\n",
    "plt.ylabel(\"Consumption\")\n",
    "\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "MAE=abs(S_N_Interp_C-R_ResultsN['Consumption'])\n",
    "plt.boxplot(MAE)\n",
    "plt.ylabel('MAE')\n",
    "plt.show()\n",
    "\n",
    "#plt.scatter(x=R_sampledf['k'], y=S_N_Interp, c=R_sampledf['AgentID'], s=5, alpha=0.3)\n",
    "#plt.scatter(x=R_sampledf['k'], y=R_ResultsN['Consumption'], c=R_sampledf['AgentID'], s=1)\n",
    "\n",
    "#plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(pd.read_csv(\"SaltelliResultsNone.csv\")))\n",
    "S_None=torch.from_numpy(np.genfromtxt(\"SaltelliResultsNone.csv\", delimiter=\",\"))\n",
    "S_Low=torch.from_numpy(np.genfromtxt(\"SaltelliResultsLow.csv\", delimiter=\",\"))\n",
    "S_High=torch.from_numpy(np.genfromtxt(\"SaltelliResultsHigh.csv\", delimiter=\",\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import curve_fit\n",
    "\n",
    "x = S_sampledf['k']\n",
    "y = S_ResultsN[\"Consumption\"]\n",
    "\n",
    "def f(x,A):\n",
    "    return A*np.log(x)+1\n",
    "    \n",
    "\n",
    "popt, pcov = curve_fit(f, x, y, method=\"trf\")\n",
    "y_fit = f(x, *popt)\n",
    "print(popt)\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(6, 4))\n",
    "ax.plot(x, y, 'o')\n",
    "ax.plot(x, y_fit, '.')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.0 ('PovertyTrapModel-master-kR78yNZD')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "394d543c160f03592c364b6e6e792ed9ade6e9b743d2876300ee9d33a907b4a0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
